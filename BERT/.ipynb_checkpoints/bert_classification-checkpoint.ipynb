{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T09:57:14.578523Z",
     "iopub.status.busy": "2025-01-05T09:57:14.578194Z",
     "iopub.status.idle": "2025-01-05T09:57:16.442803Z",
     "shell.execute_reply": "2025-01-05T09:57:16.442277Z",
     "shell.execute_reply.started": "2025-01-05T09:57:14.578503Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu121\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T09:57:20.050330Z",
     "iopub.status.busy": "2025-01-05T09:57:20.049864Z",
     "iopub.status.idle": "2025-01-05T09:57:20.614248Z",
     "shell.execute_reply": "2025-01-05T09:57:20.613696Z",
     "shell.execute_reply.started": "2025-01-05T09:57:20.050302Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import pickle as pkl\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 分词和构建词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "UNK, PAD, CLS = \"[UNK]\", \"[PAD]\", \"[CLS]\"  # 特殊符号\n",
    "MAX_VOCAB_SIZE = 10000  # 词表长度限制\n",
    "\n",
    "# 定义构建词表的函数\n",
    "def build_vocab(file_path, tokenizer, max_size, min_freq):\n",
    "    vocab_dic = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"构建词表中\"):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            content = line.split('\\t')[0]  # 假设文本在每行的第一列\n",
    "            for word in tokenizer.tokenize(content):  # 正确调用 tokenize 方法\n",
    "                vocab_dic[word] = vocab_dic.get(word, 0) + 1\n",
    "\n",
    "    # 根据频率和词表大小筛选词汇\n",
    "    vocab_list = sorted(\n",
    "        [(word, count) for word, count in vocab_dic.items() if count >= min_freq],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[:max_size]\n",
    "\n",
    "    # 创建词表字典并加入特殊符号\n",
    "    vocab_dic = {word_count[0]: idx for idx, word_count in enumerate(vocab_list)}\n",
    "    vocab_dic.update({UNK: len(vocab_dic), PAD: len(vocab_dic) + 1, CLS: len(vocab_dic) + 2})\n",
    "    return vocab_dic\n",
    "\n",
    "# 使用 transformers 的 BertTokenizer 加载中文分词器\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert_pretrain')\n",
    "\n",
    "# 构建词表\n",
    "vocab_dic = build_vocab('./data/train.txt', tokenizer=tokenizer, max_size=MAX_VOCAB_SIZE, min_freq=1)\n",
    "print(\"生成的词表大小:\", len(vocab_dic))\n",
    "# print(vocab_dic.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T02:44:56.516376Z",
     "iopub.status.busy": "2024-12-29T02:44:56.516025Z",
     "iopub.status.idle": "2024-12-29T02:44:56.522456Z",
     "shell.execute_reply": "2024-12-29T02:44:56.521948Z",
     "shell.execute_reply.started": "2024-12-29T02:44:56.516349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(config):\n",
    "    \"\"\"\n",
    "    根据提供的配置文件加载训练集、验证集和测试集，并对数据进行预处理。\n",
    "    Args:\n",
    "        config: 包含配置信息的对象，包含路径、分词器、pad_size 等。\n",
    "    Returns:\n",
    "        train, dev, test: 预处理后的训练集、验证集和测试集。\n",
    "    \"\"\"\n",
    "    def load_dataset(path, pad_size=32):\n",
    "        \"\"\"\n",
    "        加载并预处理单个数据集。\n",
    "        Args:\n",
    "            path: 数据文件路径。\n",
    "            pad_size: 序列的最大长度。如果小于 pad_size，则进行填充；如果大于，则截断。\n",
    "        Returns:\n",
    "            contents: 包含 (token_ids, label, seq_len, mask) 的数据列表。\n",
    "        \"\"\"\n",
    "        contents = []\n",
    "        with open(path, \"r\", encoding='utf-8') as f:\n",
    "            for line in tqdm(f):  # tqdm 用于显示进度条\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue  # 跳过空行\n",
    "                # 数据格式假定为 '文本\\t标签'\n",
    "                content, label = line.split('\\t')\n",
    "                token = config.tokenizer.tokenize(content)  # 分词操作\n",
    "                token = [CLS] + token  # 在序列开头添加特殊标记 [CLS]\n",
    "                seq_len = len(token)   # 序列长度\n",
    "                token_ids = config.tokenizer.convert_tokens_to_ids(token)   # 转换为 ID\n",
    "                mask = []   # 构建 mask 和 padding\n",
    "                if pad_size:\n",
    "                    if len(token) < pad_size:\n",
    "                        # 如果序列长度不足 pad_size，填充 0\n",
    "                        mask = [1] * len(token_ids) + [0] * (pad_size - len(token))\n",
    "                        token_ids += [0] * (pad_size - len(token))\n",
    "                    else:\n",
    "                        # 如果序列长度超过 pad_size，进行截断\n",
    "                        mask = [1] * pad_size\n",
    "                        token_ids = token_ids[:pad_size]\n",
    "                        seq_len = pad_size\n",
    "\n",
    "                # 将处理后的数据添加到结果列表\n",
    "                contents.append((token_ids, int(label), seq_len, mask))\n",
    "\n",
    "        return contents\n",
    "\n",
    "    # 加载训练集、验证集和测试集\n",
    "    train = load_dataset(config.train_path, config.pad_size)\n",
    "    dev = load_dataset(config.dev_path, config.pad_size)\n",
    "    test = load_dataset(config.test_path, config.pad_size)\n",
    "    return train, dev, test\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 数据封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-29T03:07:22.739460Z",
     "iopub.status.busy": "2024-12-29T03:07:22.739118Z",
     "iopub.status.idle": "2024-12-29T03:07:22.747094Z",
     "shell.execute_reply": "2024-12-29T03:07:22.746583Z",
     "shell.execute_reply.started": "2024-12-29T03:07:22.739432Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetIterater(object):\n",
    "    def __init__(self, batches, batch_size, device, model_name):\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = batches\n",
    "        self.model_name = model_name\n",
    "        self.n_batches = len(batches) // batch_size\n",
    "        self.residue = False    # 记录batch数量是否为整数\n",
    "        if len(batches) % self.n_batches != 0:\n",
    "            self.residue = True # batches不能被batch_size整除\n",
    "        self.index = 0\n",
    "        self.device = device\n",
    "    \n",
    "    def _to_tensor(self, datas):\n",
    "        x = torch.LongTensor([_[0] for _ in datas]).to(self.device)\n",
    "        y = torch.LongTensor([_[1] for _ in datas]).to(self.device)\n",
    "        # pad 前的长度（超过pad_size的设置为pad_size）\n",
    "        seq_len = torch.LongTensor([_[2] for _ in datas]).to(self.device)\n",
    "        if self.model_name == 'bert' or self.model_name == 'multi_task_bert':\n",
    "            mask = torch.LongTensor([_[3] for _ in datas]).to(self.device)\n",
    "            return (x, seq_len, mask), y\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.residue and self.index == self.n_batches:\n",
    "            batches = self.batches[self.index * self.batch_size: len(self.batches)]\n",
    "            self.index += 1\n",
    "            batches = self._to_tensor(batches)\n",
    "            return batches\n",
    "        elif self.index >= self.n_batches:\n",
    "            self.index = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            batches = self.batches[self.index * self.batch_size : (self.index + 1) * self.batch_size]\n",
    "            self.index += 1\n",
    "            batches = self._to_tensor(batches)\n",
    "            return batches\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.residue:\n",
    "            return self.n_batches + 1\n",
    "        else:\n",
    "            return self.n_batches\n",
    "\n",
    "def build_iterator(dataset, config):\n",
    "    iter = DatasetIterater(dataset, config.batch_size, config.device, config.model_name)\n",
    "    return iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T02:45:01.041280Z",
     "iopub.status.busy": "2024-12-29T02:45:01.040956Z",
     "iopub.status.idle": "2024-12-29T02:45:01.044236Z",
     "shell.execute_reply": "2024-12-29T02:45:01.043740Z",
     "shell.execute_reply.started": "2024-12-29T02:45:01.041259Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_time_dif(start_time):\n",
    "    # 获取已使用时间\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT分类模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 实现Config类代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T02:45:02.869547Z",
     "iopub.status.busy": "2024-12-29T02:45:02.869202Z",
     "iopub.status.idle": "2024-12-29T02:45:07.722057Z",
     "shell.execute_reply": "2024-12-29T02:45:07.721569Z",
     "shell.execute_reply.started": "2024-12-29T02:45:02.869526Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 10:45:04.808890: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-29 10:45:05.787816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-29 10:45:07.019664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(self, dataset):\n",
    "        self.model_name = 'bert'\n",
    "        self.data_path = './data/'\n",
    "        self.train_path = self.data_path + \"train.txt\"  # 训练集\n",
    "        self.dev_path = self.data_path + \"dev.txt\"  # 验证集\n",
    "        self.test_path = self.data_path + \"test.txt\"    # 测试集\n",
    "        self.class_list = [\n",
    "            x.strip() for x in open(self.data_path + \"class.txt\").readlines()\n",
    "        ]   # 类别名单\n",
    "        self.save_path = './cache'\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.mkdir(self.save_path)\n",
    "        self.save_path += \"/\" + self.model_name + \".pt\" # 模型训练结果\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.require_improvement = 1000 # 若超过1000batch效果还没有提升，则提前结束训练\n",
    "        self.num_classes = len(self.class_list) # 类别数\n",
    "        self.num_epochs = 3 # epoch数\n",
    "        self.batch_size = 128   # mini-batch大小\n",
    "        self.pad_size = 32  # 每句话处理成的长度（短补长截）\n",
    "        self.learning_rate = 5e-5   # 学习率\n",
    "        self.bert_path = './bert_pretrain'\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path)\n",
    "        self.bert_config = BertConfig.from_pretrained(self.bert_path + '/bert_config.json')\n",
    "        self.hidden_size = 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T02:45:09.845390Z",
     "iopub.status.busy": "2024-12-29T02:45:09.844878Z",
     "iopub.status.idle": "2024-12-29T02:45:11.123990Z",
     "shell.execute_reply": "2024-12-29T02:45:11.123441Z",
     "shell.execute_reply.started": "2024-12-29T02:45:09.845365Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "构建词表中: 10000it [00:01, 8193.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的词表大小: 4676\n",
      "cuda ./data/train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = Config('toutiao')\n",
    "# 构建词表\n",
    "vocab_dic = build_vocab('./data/test.txt', tokenizer=config.tokenizer, max_size=MAX_VOCAB_SIZE, min_freq=1)\n",
    "print(\"生成的词表大小:\", len(vocab_dic))\n",
    "print(config.device, config.train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 实现Model类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-29T03:09:35.852444Z",
     "iopub.status.busy": "2024-12-29T03:09:35.852107Z",
     "iopub.status.idle": "2024-12-29T03:09:35.856731Z",
     "shell.execute_reply": "2024-12-29T03:09:35.856254Z",
     "shell.execute_reply.started": "2024-12-29T03:09:35.852414Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        # self.bert = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "        # self.bert = AutoModel.from_pretrained(\"bert-base-chinese\")\n",
    "        self.bert = BertModel.from_pretrained(config.bert_path, config=config.bert_config)\n",
    "        self.fc = nn.Linear(config.hidden_size, config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = x[0]\n",
    "        mask = x[2]\n",
    "        # _, pooled = self.bert(context, attention_mask=mask)\n",
    "        # out = self.fc(pooled)\n",
    "        \n",
    "        outputs = self.bert(context, attention_mask=mask)\n",
    "        pooled = outputs.pooler_output\n",
    "        out = self.fc(pooled)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编写训练、测试、评估函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T02:45:25.271955Z",
     "iopub.status.busy": "2024-12-29T02:45:25.271644Z",
     "iopub.status.idle": "2024-12-29T02:45:25.275682Z",
     "shell.execute_reply": "2024-12-29T02:45:25.275126Z",
     "shell.execute_reply.started": "2024-12-29T02:45:25.271936Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "# from utils import get_time_dif\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-29T03:13:56.416567Z",
     "iopub.status.busy": "2024-12-29T03:13:56.416229Z",
     "iopub.status.idle": "2024-12-29T03:13:56.424512Z",
     "shell.execute_reply": "2024-12-29T03:13:56.423973Z",
     "shell.execute_reply.started": "2024-12-29T03:13:56.416546Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(config, model, train_iter, dev_iter):\n",
    "    start_time = time.time()\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.01\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0\n",
    "        }\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()  # 损失函数定义一次\n",
    "\n",
    "    total_batch = 0  # 记录进行到多少batch\n",
    "    dev_best_loss = float('inf')\n",
    "    last_improve = 0  # 记录上次验证集loss下降的batch数\n",
    "    flag = False  # 记录是否很久没有效果提升，用于判断是否早停\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print(f\"Epoch [{epoch + 1}/{config.num_epochs}]\")\n",
    "        for i, (trains, labels) in enumerate(tqdm(train_iter)):\n",
    "\n",
    "            outputs = model(trains)\n",
    "            model.zero_grad()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            if total_batch % 200 == 0 and total_batch != 0:\n",
    "                # 每 200 轮输出在训练集和验证集上的效果\n",
    "                true = labels.data.cpu()\n",
    "                predict = torch.max(outputs.data, 1)[1].cpu()\n",
    "                train_acc = metrics.accuracy_score(true, predict)\n",
    "                dev_acc, dev_loss = evaluate(config, model, dev_iter)\n",
    "                if dev_loss < dev_best_loss:\n",
    "                    dev_best_loss = dev_loss  # 更新最佳验证集loss\n",
    "                    torch.save(model.state_dict(), config.save_path)  # 保存模型\n",
    "                    improve = '*'\n",
    "                    last_improve = total_batch\n",
    "                else:\n",
    "                    improve = \"\"\n",
    "                time_dif = get_time_dif(start_time)\n",
    "                msg = (f\"Epoch: {epoch + 1}, Batch: {i + 1}, Iter: {total_batch}, \"\n",
    "                       f\"Train Loss: {loss.item():.2f}, Train Acc: {train_acc:.2%}, \"\n",
    "                       f\"Val Loss: {dev_loss:.2f}, Val Acc: {dev_acc:.2%}, Time: {time_dif} {improve}\")\n",
    "                print(msg)\n",
    "                model.train()\n",
    "\n",
    "            total_batch += 1\n",
    "\n",
    "            if total_batch - last_improve > config.require_improvement:\n",
    "                # 验证集loss超过指定batch没有下降，提前结束训练\n",
    "                print(\"No optimization for a long time, auto-stopping...\")\n",
    "                flag = True\n",
    "                break\n",
    "        if flag:\n",
    "            break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T02:45:30.848240Z",
     "iopub.status.busy": "2024-12-29T02:45:30.847907Z",
     "iopub.status.idle": "2024-12-29T02:45:30.852032Z",
     "shell.execute_reply": "2024-12-29T02:45:30.851497Z",
     "shell.execute_reply.started": "2024-12-29T02:45:30.848218Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(config, model, test_iter):\n",
    "    # model.load_state_dict(torch.load(config.save_path))\n",
    "    # 采用量化模型进行推理时需要关闭\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    test_acc, test_loss, test_report, test_confusion = evaluate(config, model, test_iter, test=True)\n",
    "    \n",
    "    msg = \"Test Loss: {0:>5.2}, Test Acc: {1:>6.2%}\"\n",
    "    print(msg.format(test_loss, test_acc))\n",
    "    print(\"Precision, Recall and F1-Score...\")\n",
    "    print(test_report)\n",
    "    print(\"Confusion Matrix...\")\n",
    "    print(test_confusion)\n",
    "    time_dif = get_time_dif(start_time)\n",
    "    print(\"Time usage:\", time_dif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T02:45:32.478591Z",
     "iopub.status.busy": "2024-12-29T02:45:32.478233Z",
     "iopub.status.idle": "2024-12-29T02:45:32.483542Z",
     "shell.execute_reply": "2024-12-29T02:45:32.483024Z",
     "shell.execute_reply.started": "2024-12-29T02:45:32.478567Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(config, model, data_iter, test=False):\n",
    "    # 采用量化模型进行推理时需要关闭\n",
    "    model.eval()\n",
    "    loss_total = 0\n",
    "    predict_all = np.array([], dtype=int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in data_iter:\n",
    "            outputs = model(texts)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            \n",
    "            loss_total += loss\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            predict = torch.max(outputs.data, 1)[1].cpu().numpy()\n",
    "            labels_all = np.append(labels_all, labels)\n",
    "            predict_all = np.append(predict_all, predict)\n",
    "    acc = metrics.accuracy_score(labels_all, predict_all)\n",
    "    if test:\n",
    "        report = metrics.classification_report(labels_all, predict_all, target_names=config.class_list, digits=4)\n",
    "        confusion = metrics.confusion_matrix(labels_all, predict_all)\n",
    "        return acc, loss_total / len(data_iter), report, confusion\n",
    "    return acc, loss_total / len(data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T02:45:34.143899Z",
     "iopub.status.busy": "2024-12-29T02:45:34.143552Z",
     "iopub.status.idle": "2024-12-29T02:45:34.147147Z",
     "shell.execute_reply": "2024-12-29T02:45:34.146444Z",
     "shell.execute_reply.started": "2024-12-29T02:45:34.143879Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "# from train_eval import train, test\n",
    "from importlib import import_module\n",
    "import argparse\n",
    "# from utils import build_dataset, build_iterator, get_time_dif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 加载和处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T03:08:25.673131Z",
     "iopub.status.busy": "2024-12-29T03:08:25.672804Z",
     "iopub.status.idle": "2024-12-29T03:08:59.567817Z",
     "shell.execute_reply": "2024-12-29T03:08:59.567288Z",
     "shell.execute_reply.started": "2024-12-29T03:08:25.673111Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train.txt\n",
      "Loading data for Bert Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180000it [00:30, 5993.65it/s]\n",
      "10000it [00:02, 4746.87it/s]\n",
      "10000it [00:01, 5976.95it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = \"toutiao\" # 数据集\n",
    "config = Config(dataset)\n",
    "print(config.train_path)\n",
    "\n",
    "print(\"Loading data for Bert Model...\")\n",
    "train_data, dev_data, test_data = build_dataset(config)\n",
    "train_iter = build_iterator(train_data, config)\n",
    "dev_iter = build_iterator(dev_data, config)\n",
    "test_iter = build_iterator(test_data, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-29T03:14:01.076701Z",
     "iopub.status.busy": "2024-12-29T03:14:01.076374Z",
     "iopub.status.idle": "2024-12-29T03:14:01.306423Z",
     "shell.execute_reply": "2024-12-29T03:14:01.305855Z",
     "shell.execute_reply.started": "2024-12-29T03:14:01.076680Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=768, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(config).to(config.device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-29T03:14:03.058608Z",
     "iopub.status.busy": "2024-12-29T03:14:03.058226Z",
     "iopub.status.idle": "2024-12-29T03:28:16.516622Z",
     "shell.execute_reply": "2024-12-29T03:28:16.516118Z",
     "shell.execute_reply.started": "2024-12-29T03:14:03.058585Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 201/1407 [00:49<46:52,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 201, Iter: 200, Train Loss: 0.20, Train Acc: 94.53%, Val Loss: 0.31, Val Acc: 90.38%, Time: 0:00:50 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 401/1407 [01:41<43:58,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 401, Iter: 400, Train Loss: 0.28, Train Acc: 92.97%, Val Loss: 0.27, Val Acc: 91.88%, Time: 0:01:41 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 601/1407 [02:31<31:56,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 601, Iter: 600, Train Loss: 0.32, Train Acc: 92.19%, Val Loss: 0.27, Val Acc: 91.51%, Time: 0:02:32 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 801/1407 [03:20<19:18,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 801, Iter: 800, Train Loss: 0.26, Train Acc: 92.19%, Val Loss: 0.27, Val Acc: 91.75%, Time: 0:03:21 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 834/1407 [03:27<02:22,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 167/1407 [00:44<55:52,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 167, Iter: 1000, Train Loss: 0.29, Train Acc: 89.84%, Val Loss: 0.24, Val Acc: 92.38%, Time: 0:04:13 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 367/1407 [01:35<39:52,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 367, Iter: 1200, Train Loss: 0.41, Train Acc: 87.50%, Val Loss: 0.23, Val Acc: 92.61%, Time: 0:05:03 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 567/1407 [02:27<37:39,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 567, Iter: 1400, Train Loss: 0.24, Train Acc: 89.84%, Val Loss: 0.21, Val Acc: 93.18%, Time: 0:05:55 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 767/1407 [03:16<20:30,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 767, Iter: 1600, Train Loss: 0.22, Train Acc: 92.97%, Val Loss: 0.22, Val Acc: 93.04%, Time: 0:06:45 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 967/1407 [04:06<14:05,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 967, Iter: 1800, Train Loss: 0.14, Train Acc: 95.31%, Val Loss: 0.22, Val Acc: 93.43%, Time: 0:07:34 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1167/1407 [04:55<07:41,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 1167, Iter: 2000, Train Loss: 0.09, Train Acc: 97.66%, Val Loss: 0.23, Val Acc: 93.00%, Time: 0:08:24 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1367/1407 [05:45<01:16,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 1367, Iter: 2200, Train Loss: 0.05, Train Acc: 99.22%, Val Loss: 0.22, Val Acc: 93.02%, Time: 0:09:13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1407/1407 [05:53<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 160/1407 [00:43<58:15,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 160, Iter: 2400, Train Loss: 0.12, Train Acc: 96.09%, Val Loss: 0.21, Val Acc: 93.61%, Time: 0:10:05 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 360/1407 [01:33<33:51,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 360, Iter: 2600, Train Loss: 0.19, Train Acc: 94.53%, Val Loss: 0.22, Val Acc: 93.38%, Time: 0:10:55 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 560/1407 [02:23<27:08,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 560, Iter: 2800, Train Loss: 0.10, Train Acc: 96.09%, Val Loss: 0.21, Val Acc: 93.61%, Time: 0:11:45 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 760/1407 [03:12<20:44,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 760, Iter: 3000, Train Loss: 0.16, Train Acc: 95.31%, Val Loss: 0.23, Val Acc: 93.30%, Time: 0:12:34 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 960/1407 [04:02<14:21,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 960, Iter: 3200, Train Loss: 0.04, Train Acc: 100.00%, Val Loss: 0.25, Val Acc: 93.19%, Time: 0:13:24 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1159/1407 [04:51<01:02,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 1160, Iter: 3400, Train Loss: 0.06, Train Acc: 98.44%, Val Loss: 0.24, Val Acc: 93.10%, Time: 0:14:13 \n",
      "No optimization for a long time, auto-stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(config, model, train_iter, dev_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T03:36:48.800530Z",
     "iopub.status.busy": "2024-12-29T03:36:48.800214Z",
     "iopub.status.idle": "2024-12-29T03:36:54.083035Z",
     "shell.execute_reply": "2024-12-29T03:36:54.082527Z",
     "shell.execute_reply.started": "2024-12-29T03:36:48.800508Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.21, Test Acc: 93.75%\n",
      "Precision, Recall and F1-Score...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      finance     0.9363    0.9120    0.9240      1000\n",
      "       realty     0.9754    0.9130    0.9432      1000\n",
      "       stocks     0.8286    0.9430    0.8821      1000\n",
      "    education     0.9678    0.9630    0.9654      1000\n",
      "      science     0.9141    0.8940    0.9039      1000\n",
      "      society     0.9559    0.9320    0.9438      1000\n",
      "     politics     0.9295    0.9100    0.9197      1000\n",
      "       sports     0.9831    0.9860    0.9845      1000\n",
      "         game     0.9448    0.9580    0.9513      1000\n",
      "entertainment     0.9563    0.9640    0.9602      1000\n",
      "\n",
      "     accuracy                         0.9375     10000\n",
      "    macro avg     0.9392    0.9375    0.9378     10000\n",
      " weighted avg     0.9392    0.9375    0.9378     10000\n",
      "\n",
      "Confusion Matrix...\n",
      "[[912   5  63   1   8   1   8   1   1   0]\n",
      " [ 15 913  42   2   3   8   5   2   3   7]\n",
      " [ 28   4 943   0  15   0   8   0   1   1]\n",
      " [  4   1   1 963   0   7  12   1   3   8]\n",
      " [  1   1  37   4 894  12  10   2  31   8]\n",
      " [  4   4   4  13   5 932  20   3   2  13]\n",
      " [  8   5  39   8  15   9 910   1   2   3]\n",
      " [  1   3   3   0   1   1   1 986   0   4]\n",
      " [  0   0   5   1  27   4   4   1 958   0]\n",
      " [  1   0   1   3  10   1   1   6  13 964]]\n",
      "Time usage: 0:00:05\n"
     ]
    }
   ],
   "source": [
    "test(config,model, test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
